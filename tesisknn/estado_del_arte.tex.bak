\chapter[Estado del Arte]{\label{ch:estado-arte}Estado del Arte}

El algoritmo kNN \cite{hart1966asymptotic}, \cite{cover1967nearest} se aplica ampliamente en reconocimiento de patrones y minería de datos para clasificación, dada su simplicidad y baja tasa de errores. Una consulta kNN tiene como objetivo recuperar los elementos K más similares a una consulta q, donde la similitud viene dada por una función de similitud.\\


\section{Algoritmos secuenciales y multi-núcleo}
Unos de los métodos clásicos y más simples de clasificación es llamado vecino más cercano, del ingles k-Nearest Neighbour (kNN) fue originalmente propuesta por Cover y Hart \cite{hart1966asymptotic}, \cite{cover1967nearest}. Una razón para el uso de este método es su simplicidad conceptual que conduce a la programación directa, si no necesariamente la más eficiente. Este algoritmo utiliza la idea central de la distancia euclidiana entre dos puntos en el espacio, a partir de este cálculo se analiza la similitud entre todos los puntos existentes.
En un artículo posterior, Hart \cite{hilborn1968dg} sugirió un medio de disminución de la memoria y los requisitos de computación. Este artículo introduce una técnica, el método del vecino más cercano reducido que puede conducir a más ahorros. Los resultados de esta técnica se demuestran aplicándola a los datos de $"Iris"$ \cite{freeman1969experiments}.

El algoritmo kNN \cite{knn1} \cite{cover1967nearest} tiene grandes requisitos de almacenamiento, pero pueden reducir significativamente el trabajo de aprendizaje de otro tipo de técnicas y aumentar la precisión en la clasificación. Uno de los problemas más grandes que presenta este algoritmo es el alto costo de procesamiento y memoria para revolver las consultas.\\

Se aplica ampliamente en el reconocimiento de patrones y en clasificación para minería de datos, debido a su simplicidad y baja tasa de error. Antes de la aparición masiva de plataformas paralelas, la realización por fuerza bruta (exhaustivamente) no se consideraba como una opción válida, especialmente para grandes bases de datos de entrenamiento y espacios de alta densidad. Para reducir el espacio de búsqueda y evitar tantos cálculos de distancia como sea posible, se han propuesto muchos enfoques de indexación. La mayoría de los métodos de recuperación se basan en kd-trees \cite{bentley1979data}. Hay una gran cantidad de trabajo sobre las adaptaciones de la estructura básica kd-tree para el problema kNN \cite{brisaboa2008clustering} \cite{paredes2009egnat}. También se han propuesto estructuras no-tree que dividen eficientemente el espacio de búsqueda \cite{chavez2000effective} \cite{brisaboa2006similarity} .Las implementaciones basadas en MPI que utilizan estas estructuras también aparecen con mucha frecuencia en la literatura \cite{plaku2007distributed}.\\
La principal desventaja de estos métodos es que necesitan construir y mantener estructuras de datos complejas para el conjunto de datos de referencia. De manera que, kNN se implementa típicamente utilizando métodos de fuerza bruta. 

Por lo tanto, las soluciones actuales de GPU han sido de alguna manera más simples y menos eficientes desde el punto de vista del algoritmo. Por ejemplo, Benjamin Bustos et al. \cite{bustos2006graphics} propuso una implementación no-CUDA explotar memorias de textura GPU. Su implementación sólo busca el elemento mínimo, lo que simplifica significativamente el problema.

El cálculo de la distancia exhaustiva en conjunción con la clasificación en paralelo se propuso en \cite{garcia2008fast}, \cite{kuang2009practical}. Vecente Garcia et al. \cite{garcia2008fast} propuso un orden de inserción paralelo modificado con el fin de obtener sólo los K elementos más cercanos, mientras que Kuang et al. \cite{kuang2009practical} propuso un mejor Radix-sort para realizar la clasificación final.
\\
Ver algoritmos de referencias: algoritmo \ref{lst:knn} y algoritmo \ref{lst:knn2}.


\begin{algorithm}
\begin{lstlisting}[language=C]
for (i = 0; i < N_QUERIES; i++) {
	n_elem = 0;
	for (j = 0; j < N_DB; j++) {    
		d = distancia(Consultas[i], DB[j]);
		if(n_elem<TOPK){
			e_temp.dist = d;
			e_temp.ind = j;
			inserta(heap, &e_temp, &n_elem);
		}
		else{
			if (d < topH(heap, &n_elem)) {
				e_temp.dist = d;
             	e_temp.ind = j;
				popush(heap, &n_elem, &e_temp);
		}}
	}
        for (int k = 0; k < TOPK; ++k){
        	extrae(heap, &n_elem, &e_temp);
        	answer[i*TOPK+k].ind = e_temp.ind;
        	answer[i*TOPK+k].dist = e_temp.dist;
        }
}
\end{lstlisting}
\caption{\emph{\label{lst:knn}} Proceso iterativo de una consulta kNN.}
\end{algorithm}


\begin{algorithm}
\begin{lstlisting}[language=C]
#pragma omp master
for (i = tid; i < N_QUERIES; i += procs) {           
	n_elem = 0;
    for (j = 0; j < N_DB; j++) {           
    	d = distancia(Consultas[i], DB[j]);               
        if(n_elem<TOPK){
        	e_temp.dist = d;
        	e_temp.ind = j;
        	inserta(heap, &e_temp, &n_elem);
        }
        else{
        	if (d < topH(heap, &n_elem)) {
            	e_temp.dist = d;
            	e_temp.ind = j;
            }}
        }
        for (j = 0; j < TOPK ; j++) {
        	extrae(heap, &n_elem, &e_temp);
        	answer[i*TOPK+j].ind = e_temp.ind;
        	answer[i*TOPK+j].dist = e_temp.dist;
       	}
}

#pragma omp barrier
\end{lstlisting}
\caption{\emph{\label{lst:knn2}} Proceso iterativo de una consulta kNN multi-core.}
\end{algorithm}

\section{kNN Xeon Phi}

El trabajo relacionado para resolver consultas por rango es amplio, pero destacan los métodos que utilizan indexación, tales como, la Lista de Clusters (LC) \cite{tellez2012polyphasic}, EGNAT \cite{egnat06}, DSACL$+-$tree \cite{britos2012dsacl}, M-Index  \cite{novak2011metric} o Polyphasic Metric Index . Todos ellos intentan descartar elementos de la base de datos para evitar comparar cada elemento contra la consulta.
\\
En el caso de las consultas de kNN, uno de los principales problemas con los algoritmos de kNN es encontrar a los vecinos lo más rápido posible. Se han desarrollado varios enfoques. En \cite{gao2009efficient}, se mejoran las búsquedas entre vecinos más cercanos con la división de datos índice (árbol-R), la mejor primera recuperación y la inversa. En caso de búsquedas de objetos en movimiento, Transformado Minkowski Suma se usa para detectar intersección de regiones y árbol transversal algoritmos para realizar de manera efectiva rango y kNN consultas. Barrientos et al. \cite{barrientos2011knn} muestra una solución exhaustiva para kNN en GPU obteniendo una alta velocidad sobre la CPU. Recientemente, en \cite{chavez2015near} los autores definieron un marco para construir índices y usan firmas de referencias K-más cercanas para mejorar el representación eficiente del espacio para trabajar con bases de datos más grandes. Ver algoritmo \ref{lst:knnxeon}


\begin{algorithm}
\begin{lstlisting}[language=C]
   #pragma offload target(mic:0) in(dim) in(db_vector:length(num_db*dimaux)) in(queries_vector:length(num_queries*dimaux)) out(answer:length(k*num_queries))
   {
      #pragma omp parallel private(i, j, thread_num) shared(db_vector, num_db, queries_vector, num_queries, dimaux, k, answer, num_threads)
      {
         
         Elem *heap;
         heap = (Elem *)malloc(sizeof(Elem)*k);
         #pragma omp master
         {
            num_threads = omp_get_num_threads();
         }
         #pragma omp barrier
         thread_num = omp_get_thread_num();
         int n_elem;
         Elem e_temp;
         double d;

         
         for(i=thread_num*dimaux; i<num_queries*dimaux; i+=num_threads*dimaux){
            n_elem = 0;
            for(j=0; j<k; j++){
               e_temp.dist = distancia(&(queries_vector[i]), &(db_vector[j*dimaux]), dimaux);
               e_temp.ind = j;
               inserta(heap, &e_temp, &n_elem);
            }

            for(j=k; j<num_db; j++){
               d = distancia(&(queries_vector[i]), &(db_vector[j*dimaux]), dimaux);
               if(d < topH(heap, &n_elem))
                  {
                     e_temp.dist = d;
                     e_temp.ind = j;
                     popush(heap, &n_elem, &e_temp);
                  }
            }

            for(j=0; j<k; j++){
               extrae(heap, &n_elem, &e_temp);
               answer[(i/dimaux)*k+j].ind = e_temp.ind;
               answer[(i/dimaux)*k+j].dist = e_temp.dist;
            }


         }
         free(heap);
      }
   }   
\end{lstlisting}
\caption{\emph{\label{lst:knnxeon}} Proceso iterativo de una consulta kNN Xeon phi.}
\end{algorithm}


\section{kNN GPU}

Antes del advenimiento de plataformas masivamente paralelas, la exploración de fuerza bruta no solía considerarse una opción válida, especialmente para grandes bases de datos de entrenamiento y espacios de alta dimensión. Para podar el espacio de búsqueda y evitar tantos cómputos de distancia como sea posible, se han propuesto muchos enfoques de indexación. Los autores de \cite{barrientos2011knn}, \cite{pan2011fast} usan algoritmos de indexación y estructuras de datos en GPU para resolver consultas kNN.
\\
En \cite{cayton2012accelerating}, los autores utilizan una estructura de datos llamada RBC (Random Ball Cover), que usa un conjunto de elementos representativos $X = x_1, x_2, \dots , x_n$, y para cada conjunto xia de elementos cercanos está asociado con eso. Luego, la propiedad de desigualdad triangular se usa para descartar elementos utilizando la estructura RBC, que también se implementó en la GPU en el mismo estudio. En \cite{barrientos2011knn}, se usan dos índices diferentes en la GPU para consultas kNN: el índice SSS \cite{brisaboa2006similarity} (índice de selección espacial disperso), que se basa en pivotes, y la lista de clústeres \cite{chavez2005compact}	 (lista de clústeres), que se basa en la agrupación. El SSS-Index usa una tabla de pivotes para tratar de descartar cada elemento usando su distancia a los pivotes. La Lista de conglomerados crea grupos de elementos e intenta descartar cada grupo utilizando las propiedades de desigualdad del triángulo. Todos los elementos en cada grupo no descartado deben compararse con la consulta.
\\
Los algoritmos exhaustivos utilizados para resolver consultas de kNN en GPU se pueden dividir en estudios basados en algoritmos de ordenamiento y aquellos basados en otros tipos. El primero, como \cite{garcia2008fast},\cite{kuang2009practical}, ordena todas las distancias entre la consulta y los elementos de la base de datos, y los primeros k elementos de la matriz ordenada son los resultados. Los algoritmos de clasificación tales como clasificación de ordenación basada en CUDA y clasificación de inserción se han utilizado para resolver consultas de kNN en la GPU, aunque los métodos de clasificación no tuvieron un buen rendimiento en trabajos anteriores \cite{barrientos2011knn}. Los enfoques basados en GPU, que no clasifican todas las distancias, son más eficientes en la resolución de consultas kNN. Por ejemplo, en \cite{barrientos2011knn} los autores proponen un algoritmo basado en GPU llamado Batch Heap-Reduction, que logra un mejor rendimiento que el algoritmo GPU-Quicksort \cite{cederman2009gpu} basado en ordenamiento, y también mayor velocidad que los algoritmos de indexación con alta espacios dimensionales. El algoritmo Batch Heap-Reduction utiliza varios hilos en un bloque CUDA, mediante un algoritmo de tres pasos para obtener los resultados K finales, pero dado que requiere una gran cantidad de memoria compartida, no es capaz de resolver consultas kNN con alto K Los autores de \cite{beliakov2012improving} también utilizan un algoritmo de selección llamado cp-select \cite{beliakov2012computing2} que mostró una mejora considerable en el rendimiento sobre los enfoques anteriores basados en la clasificación.
\\
Existe una versión de GPU de Quicksort que fue propuesta por Daniel Cederman y Philippas Tsigas \cite{cederman2009gpu} que mostró ser más rápido que los algoritmos de clasificación anteriores. Este trabajo se basa en la propuesta que también calcula exhaustivamente todas las distancias, pero utiliza una metodología específica basada en heap para encontrar los K elementos más cercanos, propuesta por Ricardo Barrientos y José Gómez \cite{barrientos2010heap}
\\ Ver algoritmo \ref{lst:knnCUDA} y algoritmo \ref{lst:bacth}
\begin{algorithm}
\begin{lstlisting}[language=C]

  while(contQ < N_QUERIES){
    contQ += Q;
    if (contQ > N_QUERIES)
    N_BLOQUES = N_QUERIES - (contQ-Q);
    printf("\nN_BLOQUES = %d :: T_per_BLOCK = %d\n", N_BLOQUES, T_per_BLOCK);
    
    Batch_Heap_Reduction<<<N_BLOQUES, T_per_BLOCK>>> (Elems, (int)pitch, HEAPS_dev, (int)pitch_H, QUERY_dev, (int)pitch_Q, arr_Dist, (int)pitch_Dist, Q*cont, res_final);
    
    if (cudaSuccess != cudaMemcpy((double *)res_final_H, (double *)res_final, sizeof(double)*Q*TOPK, cudaMemcpyDeviceToHost)){  
      printf("\nERROR 41 :: cudaMemcpy :: iteraH\n");
      cudaThreadExit();
      return 0;
    }
    cont++;
  }
  
\end{lstlisting}
\caption{\emph{\label{lst:knnCUDA}}Proceso iterativo de una consulta kNN en GPU.}
\end{algorithm}

\begin{algorithm}
\begin{lstlisting}[mathescape=true, language=C]
Heap Reduction()
	{D = Arreglo de distancias para ser reducidas.}
	{DH$_i$ = Heap del hilo i almacenado en la memoria del dispositivo}
	{SH$_i$ = Heap del hilo i almacenado en la memoria compartida}
	{Size$_{warp}$ = Tamano de un warp (actualmente es de 32)}
	{tid = ID unico para el hilo entre todos los hilos de todos los bloques.}
	{TxBlock = Hilos por bloque del nucleo.}
	{Cada hilo almacena los elementos en un heap}
	for i = tid; i < D.size(); i+=T xBlock do
		if DH$_{tid}$.size() < K then
			DH$_{tid}$.push(D[i])
		else
			if DH$_{tid}$.top() > D[i] then
				DH$_{tid}$.popush(D[i])
			end if
		end if
	end for
	__syncthreads()
	{Un warp almacena los elementos de los heap previos en Size$_{warp}$  memoria compartida de heaps}
	if tid < Size$_{warp}$ then
		for i = tid; i < TxBlock; i+=Size$_warp$ do
			x = DH$_{i}$.pop()
			if SH$_{tid}$.size() < K then
				SH$_{tid}$.push(x)
			else
				if SH$_{tid}$.top() > x then
					SH$_{tid}$.popush(x)
				end if
			end if
		end for
	end if
	__syncthreads()
	{Un hilo visita exhaustivamente SH y selecciona el primer K}
	if tid == 0 then
		obtener_primer_K(SH)
	end if
  
\end{lstlisting}
\caption{\emph{\label{lst:bacth}}Batch Heap Reduction.}
\end{algorithm}


